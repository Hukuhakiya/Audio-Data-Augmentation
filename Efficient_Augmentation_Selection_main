{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b67d3a",
   "metadata": {
    "papermill": {
     "duration": 0.011901,
     "end_time": "2024-09-06T17:42:24.158397",
     "exception": false,
     "start_time": "2024-09-06T17:42:24.146496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LIBRARY PULL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac76d1b",
   "metadata": {
    "papermill": {
     "duration": 0.011827,
     "end_time": "2024-09-06T17:42:24.181901",
     "exception": false,
     "start_time": "2024-09-06T17:42:24.170074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model is a pretrained model from UrbanSound8k, and it uses 8 layers with 128 inputs in the first layer using a Keras.Sequential structure. The generic audio processing utilizes the features of the Librosa library together with the array characteristics of the Pandas and NumPy libraries. Some other visualization and training libraries are also included in the library imports as side tools or potential improvements to the script in observing the analysis and the complete characteristics of the behavior of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45d3fc0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:24.207024Z",
     "iopub.status.busy": "2024-09-06T17:42:24.206597Z",
     "iopub.status.idle": "2024-09-06T17:42:43.824916Z",
     "shell.execute_reply": "2024-09-06T17:42:43.823322Z"
    },
    "papermill": {
     "duration": 19.634379,
     "end_time": "2024-09-06T17:42:43.828015",
     "exception": false,
     "start_time": "2024-09-06T17:42:24.193636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting resampy\r\n",
      "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from resampy) (1.26.4)\r\n",
      "Requirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.10/site-packages (from resampy) (0.58.1)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.53->resampy) (0.41.1)\r\n",
      "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: resampy\r\n",
      "Successfully installed resampy-0.4.3\r\n"
     ]
    }
   ],
   "source": [
    "# Basic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "!pip install resampy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddadc549",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:43.857090Z",
     "iopub.status.busy": "2024-09-06T17:42:43.856305Z",
     "iopub.status.idle": "2024-09-06T17:42:58.344534Z",
     "shell.execute_reply": "2024-09-06T17:42:58.342990Z"
    },
    "papermill": {
     "duration": 14.506183,
     "end_time": "2024-09-06T17:42:58.347442",
     "exception": false,
     "start_time": "2024-09-06T17:42:43.841259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 17:42:46.122141: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-06 17:42:46.122276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-06 17:42:46.282309: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Libraries for Classification and building Models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1dff6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.390546Z",
     "iopub.status.busy": "2024-09-06T17:42:58.389818Z",
     "iopub.status.idle": "2024-09-06T17:42:58.518134Z",
     "shell.execute_reply": "2024-09-06T17:42:58.516723Z"
    },
    "papermill": {
     "duration": 0.147872,
     "end_time": "2024-09-06T17:42:58.520987",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.373115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project Specific Libraries\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob \n",
    "import skimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e05037",
   "metadata": {
    "papermill": {
     "duration": 0.012962,
     "end_time": "2024-09-06T17:42:58.547310",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.534348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AUDIO AUGMENTATION FUNCTION DEFINITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcac18f",
   "metadata": {
    "papermill": {
     "duration": 0.012931,
     "end_time": "2024-09-06T17:42:58.573522",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.560591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Explanations and Input Parameter Properties for Augmentation Methods\n",
    "* arrang\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449921f",
   "metadata": {
    "papermill": {
     "duration": 0.012724,
     "end_time": "2024-09-06T17:42:58.600622",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.587898",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadf6da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.629862Z",
     "iopub.status.busy": "2024-09-06T17:42:58.628804Z",
     "iopub.status.idle": "2024-09-06T17:42:58.652591Z",
     "shell.execute_reply": "2024-09-06T17:42:58.651346Z"
    },
    "papermill": {
     "duration": 0.041576,
     "end_time": "2024-09-06T17:42:58.655306",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.613730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def arrange_duration(data, sample_rate, duration, decimal = True):\n",
    "    \"\"\"\n",
    "    the function allows the manual sampling and duration specification\n",
    "    also returns the original data for further preprocessing\n",
    "    \"\"\"\n",
    "    if duration <= 0:\n",
    "        return data\n",
    "    \n",
    "    data_duration = librosa.get_duration(y = data, sr = sample_rate)\n",
    "    duration_ratio = duration / data_duration\n",
    "    \n",
    "    new_data = []\n",
    "    for i in range(int(duration_ratio)):\n",
    "        new_data = np.append(new_data, data)\n",
    "        \n",
    "    if decimal:\n",
    "        decimal_duration = int(len(data) * (duration_ratio % 1))\n",
    "        new_data = np.append(new_data, data[:decimal_duration])\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def squared_norm(vector):\n",
    "    \"\"\"\n",
    "    used for SNR integration into the noise function\n",
    "    \"\"\"\n",
    "    return np.sum(np.square(vector))\n",
    "\n",
    "def add_noise(data, snr_dbs, noise_factor):\n",
    "    \"\"\"\n",
    "    white noise addition through the formulation in reference to https://pytorch.org/audio/main/generated/torchaudio.functional.add_noise.html\n",
    "    \"\"\"\n",
    "    noise = np.random.randn(len(data))\n",
    "    sq_norm_noise, sq_norm_data = squared_norm(noise), squared_norm(data)\n",
    "    noisy_data = np.sqrt((sq_norm_data/sq_norm_noise)*(10**(-snr_dbs/10)))*noise_factor*noise + data\n",
    "    return noisy_data\n",
    "\n",
    "def shift_sound(data, shift_factor):\n",
    "    \"\"\"\n",
    "    shifts the audio waveform in time domain\n",
    "    shift is randomized as per the shift_factor provided in [0,1]\n",
    "    \"\"\"\n",
    "    shift_factor = np.random.randint(0, shift_factor * len(data) + 1)\n",
    "    rolled_data = np.roll(data, shift_factor)\n",
    "    return rolled_data\n",
    "\n",
    "def shift_sound_add(data, shift_factor):\n",
    "    \"\"\"\n",
    "    adds the shifted sound onto the original audio\n",
    "    creates a reflection like effect\n",
    "    \"\"\"\n",
    "    if shift_factor != 0:\n",
    "        shift_factor = np.random.randint(0, shift_factor * len(data) + 1)\n",
    "        rolled_data = np.roll(data, shift_factor)\n",
    "        rolled_data = rolled_data + data\n",
    "        return rolled_data\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def change_pitch(data, sample_rate, pitch_factor):\n",
    "    \"\"\"\n",
    "    direct pitch change using librosa.effects library\n",
    "    \"\"\"\n",
    "    if pitch_factor != 0:\n",
    "        changed_pitch_data = librosa.effects.pitch_shift(data, sr = sample_rate, n_steps = pitch_factor)\n",
    "        return changed_pitch_data\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "def change_speed(data, speed_rate):\n",
    "    \"\"\"\n",
    "    time stretchs through librosa.effects library, changes the processing speed rate\n",
    "    \"\"\"\n",
    "    if speed_rate !=1:\n",
    "        stretched_data = librosa.effects.time_stretch(data, rate = speed_rate)\n",
    "        return stretched_data\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "def rand_cancel(data, crop_factor):\n",
    "    \"\"\"\n",
    "    makes some portion of the audio, either in mel-frequency or time domain vanish\n",
    "    in small portions, it is found effective augmenting the dataset\n",
    "    for a more developed version refer to doi: 10.21437/Interspeech.2019-2680\n",
    "    \"\"\"\n",
    "    if crop_factor != 0:\n",
    "        data_length = len(data)\n",
    "        lower_bound = np.random.randint(0, data_length)\n",
    "        upper_bound = min(lower_bound + round(crop_factor * data_length), data_length)  # Ensure it doesn't exceed bounds\n",
    "        rand_num = random.random() # Randomization to prevent pattern recog.\n",
    "\n",
    "        # randomization as per the different volumes\n",
    "        if 0.1 <= rand_num <= 0.95:\n",
    "            data[lower_bound:upper_bound] = 0\n",
    "\n",
    "        return data\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "\n",
    "def main_effect(data, sample_rate, added_shift_factor = 0, crop_factor=0, noise_factor = 0, snr_dbs = 1, shift_factor = 0, pitch_factor = 0, speed_rate = 1, duration = 0, decimal = True):\n",
    "    \"\"\"\n",
    "    merges all the effect functions to give the complete form of the preprocessed audio data\n",
    "    \"\"\"\n",
    "    final_data = arrange_duration(\n",
    "        change_speed(change_pitch(\n",
    "            shift_sound(add_noise(\n",
    "                rand_cancel(\n",
    "                    shift_sound_add(data, added_shift_factor), crop_factor), snr_dbs, noise_factor), shift_factor), sample_rate, pitch_factor), speed_rate), sample_rate, duration, decimal)\n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcd561f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.685583Z",
     "iopub.status.busy": "2024-09-06T17:42:58.685169Z",
     "iopub.status.idle": "2024-09-06T17:42:58.693028Z",
     "shell.execute_reply": "2024-09-06T17:42:58.691842Z"
    },
    "papermill": {
     "duration": 0.025114,
     "end_time": "2024-09-06T17:42:58.695468",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.670354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # testing for the augmentation corruption levels through audio listenings, going to have this through the addition of noise\n",
    "# # call the function to observe the augmented version and to display the mel spectogram, let's try to observe this on different groups of audio and\n",
    "# # different types*** of augmentation methods to determine a level to prevent possible corruption, an average low level reliable model\n",
    "# # change for possible referencing positions\n",
    "\n",
    "# def audio_inspector(data_path, aug=0):\n",
    "#     \"\"\"\n",
    "#     gives the output to mel-freq and linear-freq power spectrograms\n",
    "#     also gives the audio put in, enabling the user to play the audio\n",
    "#     \"\"\"\n",
    "#     # aug = [crop_factor, noise_factor, snr_dbs, shift_factor, pitch_factor, speed_rate]\n",
    "#     \"\"\"\n",
    "#     inspects the audio and the linear-spectogram of the audio\n",
    "#     before and after the augmentation to observe the possible corruption\n",
    "#     \"\"\"\n",
    "#     #data_path format -- 'foldX/111111-1-1-1.wav' == 'foldX/xxxxxx-x-x-x.wav'\n",
    "#     data_path = '../input/urbansound8k/' + data_path\n",
    "#     audio, sample_rate = librosa.load(data_path)\n",
    "\n",
    "#     # visualization for the clear audio\n",
    "#     plt.figure(figsize=(25, 15))\n",
    "#     audio_spec_noaug = librosa.amplitude_to_db(librosa.stft(audio), np.max)\n",
    "#     plt.subplot(4,2,1)\n",
    "#     librosa.display.specshow(audio_spec_noaug, y_axis='linear')\n",
    "#     plt.colorbar(format='%+2.0f dB')\n",
    "#     plt.title('Linear-freq Power Spectogram for the Data /wo Aug')\n",
    "\n",
    "#     display(Audio(data=audio, rate=sample_rate))\n",
    "\n",
    "#     # augmented version\n",
    "#     # aug = [crop_factor, noise_factor, snr_dbs, shift_factor, pitch_factor, speed_rate]\n",
    "#     audio_aug = main_effect(audio, sample_rate, crop_factor=aug[0], noise_factor = aug[1], \n",
    "#             snr_dbs = aug[2], shift_factor = aug[3], pitch_factor = aug[4], \n",
    "#             speed_rate = aug[5], duration = 0, decimal = True)\n",
    "\n",
    "#     # visualization for the augmented data\n",
    "#     plt.figure(figsize=(25, 15))\n",
    "#     audio_spec_aug = librosa.amplitude_to_db(librosa.stft(audio_aug), np.max)\n",
    "#     plt.subplot(4,2,1)\n",
    "#     librosa.display.specshow(audio_spec_aug, y_axis='linear')\n",
    "#     plt.colorbar(format='%+2.0f dB')\n",
    "#     plt.title('Linear-freq Power Spectogram for the Data /w Aug')\n",
    "\n",
    "#     display(Audio(data=audio_aug, rate=sample_rate))\n",
    "    \n",
    "# def plot_waveform(data, sample_rate):\n",
    "#     \"\"\"\n",
    "#     visualizes the waveform in time domain, as in amplitudes\n",
    "#     meaningful together with the frequency spectrograms\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(14, 5))\n",
    "#     librosa.display.waveplot(data, sr=sample_rate, alpha=0.7)\n",
    "#     plt.title('Audio Waveform')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a56d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.724708Z",
     "iopub.status.busy": "2024-09-06T17:42:58.723665Z",
     "iopub.status.idle": "2024-09-06T17:42:58.736057Z",
     "shell.execute_reply": "2024-09-06T17:42:58.734833Z"
    },
    "papermill": {
     "duration": 0.029602,
     "end_time": "2024-09-06T17:42:58.738666",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.709064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parser(data, added_shift_factor = 0, crop_factor = 0, crop_freq = 1, noise_factor = 0, snr_dbs = 1, shift_factor = 0, pitch_factor = 0, speed_rate = 1, duration = 0, decimal = True, aug = False):\n",
    "    \"\"\"\n",
    "    takes the cluster data and processes each audio piece one by one\n",
    "    if aug, augments the dataset as well\n",
    "    takes the mfcc, mel-frequency cepstrum, using STFT and mel-spectrogram transformation\n",
    "    creates mfcc dataset, through the means\n",
    "    \"\"\"\n",
    "    feature = []\n",
    "    label = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        file_name = '../input/urbansound8k/fold' + str(data[\"fold\"][i]) + '/' + data[\"slice_file_name\"][i]\n",
    "        X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        \n",
    "        # augment the data\n",
    "        if aug:\n",
    "            X = main_effect(X, sample_rate=sample_rate, added_shift_factor=added_shift_factor, snr_dbs=snr_dbs, \n",
    "                            crop_factor=0, noise_factor=noise_factor, shift_factor=shift_factor, pitch_factor=pitch_factor, speed_rate=speed_rate, duration=duration, decimal=aug)\n",
    "            \n",
    "        # extract mfcc feature from data\n",
    "        if crop_freq: \n",
    "            # cropping in the mel-freq domain      \n",
    "            mels = np.mean(rand_cancel(data = librosa.feature.melspectrogram(y=X, sr=sample_rate), crop_factor=crop_factor).T,axis=0)\n",
    "        else:         \n",
    "            # cropping in the time domain      \n",
    "            X = rand_cancel(data=X, crop_factor=crop_factor)\n",
    "            mels = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0)\n",
    "        \n",
    "        feature.append(mels)\n",
    "        label.append(data[\"classID\"][i])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return feature, label, start_time, end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a7f69b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.767064Z",
     "iopub.status.busy": "2024-09-06T17:42:58.766632Z",
     "iopub.status.idle": "2024-09-06T17:42:58.774271Z",
     "shell.execute_reply": "2024-09-06T17:42:58.773121Z"
    },
    "papermill": {
     "duration": 0.024695,
     "end_time": "2024-09-06T17:42:58.776659",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.751964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(feature, label):\n",
    "    \"\"\"\n",
    "    puts the data into array formation for further ML analysis\n",
    "    split the testing and training data for training and validation processes\n",
    "    shapes as per the pretrained model\n",
    "    \"\"\"\n",
    "    X = np.array(feature)\n",
    "    Y = np.array(label)\n",
    "#     data = temp.transpose()\n",
    "    \n",
    "#     X_ = data[:, 0]\n",
    "#     Y = data[:, 1]\n",
    "#     X = np.empty([8732, 128])\n",
    "    \n",
    "#     for i in range(8732):\n",
    "#         X[i] = (X_[i])\n",
    "    \n",
    "    Y = to_categorical(Y)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)\n",
    "    \n",
    "    X_train = X_train.reshape(-1, 16, 8, 1)\n",
    "    X_test = X_test.reshape(-1, 16, 8, 1)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0788ca4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.804957Z",
     "iopub.status.busy": "2024-09-06T17:42:58.804524Z",
     "iopub.status.idle": "2024-09-06T17:42:58.816958Z",
     "shell.execute_reply": "2024-09-06T17:42:58.815821Z"
    },
    "papermill": {
     "duration": 0.029614,
     "end_time": "2024-09-06T17:42:58.819504",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.789890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(train = False, model_name = \"Original_Model\", X_test = 0, X_train = 0, Y_test = 0, Y_train = 0, epochs = 90, batch_size = 30):\n",
    "    \"\"\"\n",
    "    trains the pretrained model as per the dataset given in\n",
    "    creates the model and returns the model and the training time\n",
    "    if no training is needed returns the model from specified data_path by model_name\n",
    "    \"\"\"\n",
    "    if train:\n",
    "        start_time = time.time()\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = (16, 8, 1)))\n",
    "        model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
    "        model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024, activation = \"tanh\"))\n",
    "        model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "        print(epochs)\n",
    "        model.fit(x=X_train, y=Y_train, batch_size=batch_size, epochs=90, validation_data=(X_test, Y_test))\n",
    "        \n",
    "        model.save(model_name+'.keras')\n",
    "        \n",
    "        end_time = time.time()\n",
    "        training_time = (end_time-start_time)/60\n",
    "        \n",
    "        return model, training_time\n",
    "        \n",
    "    else:\n",
    "        loaded_model = tf.keras.models.load_model(model_name)\n",
    "        return loaded_model\n",
    "#     when saved will return the previous model, for the train_model is called with train=False argument later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d874f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.848084Z",
     "iopub.status.busy": "2024-09-06T17:42:58.847644Z",
     "iopub.status.idle": "2024-09-06T17:42:58.855525Z",
     "shell.execute_reply": "2024-09-06T17:42:58.854255Z"
    },
    "papermill": {
     "duration": 0.025443,
     "end_time": "2024-09-06T17:42:58.858277",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.832834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_accuracy(model, X_train, X_test, Y_train, Y_test):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    score_test = model.evaluate(X_test, Y_test)\n",
    "    \n",
    "    predictions = model.predict(X_train)\n",
    "    score_train = model.evaluate(X_train, Y_train)\n",
    "    \n",
    "    test_result = score_test[1]\n",
    "    train_result = score_train[1]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    eval_time = (end_time-start_time)/60\n",
    "    \n",
    "    return train_result, test_result, eval_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0841976a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.887066Z",
     "iopub.status.busy": "2024-09-06T17:42:58.886241Z",
     "iopub.status.idle": "2024-09-06T17:42:58.907517Z",
     "shell.execute_reply": "2024-09-06T17:42:58.906297Z"
    },
    "papermill": {
     "duration": 0.038714,
     "end_time": "2024-09-06T17:42:58.910212",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.871498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing for the augmentation corruption levels through audio listenings, going to have this through the addition of noise\n",
    "# call the function to observe the augmented version and to display the mel spectogram, let's try to observe this on different groups of audio and\n",
    "# different types*** of augmentation methods to determine a level to prevent possible corruption, an average low level reliable model\n",
    "# change for possible referencing positions\n",
    "# augmentation_list_format = [noise_flag, crop_freq_time_flag, noise_factor, shift_factor, pitch_factor, speed_rate, time_or_freq_crop_factor, reflection_factor]\n",
    "\n",
    "def audio_inspector(data_path, spectrogram_type, aug=[0, 1, 0, 0, 0, 1, 0, 0]):\n",
    "    \"\"\"\n",
    "    gives the output to mel-freq and linear-freq power spectrograms\n",
    "    also gives the audio put in, enabling the user to play the audio\n",
    "    \"\"\"\n",
    "    # aug = [crop_factor, noise_factor, snr_dbs, shift_factor, pitch_factor, speed_rate]\n",
    "    \"\"\"\n",
    "    inspects the audio and the linear-spectogram of the audio\n",
    "    before and after the augmentation to observe the possible corruption\n",
    "    \"\"\"\n",
    "    \n",
    "    #data_path format -- 'foldX/111111-1-1-1.wav' == 'foldX/xxxxxx-x-x-x.wav'\n",
    "    data_path = '../input/urbansound8k/' + data_path\n",
    "    audio, sample_rate = librosa.load(data_path)\n",
    "\n",
    "    # visualization for the clear audio\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    \n",
    "    if spectrogram_type == 'mel':\n",
    "        audio_spec_noaug = librosa.feature.melspectrogram(y=audio, sr=sample_rate)\n",
    "        audio_spec_noaug = librosa.power_to_db(audio_spec_noaug, ref=np.max)\n",
    "        plt.subplot(4,2,1)\n",
    "        librosa.display.specshow(audio_spec_noaug, y_axis=spectrogram_type)\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Mel-freq Power Spectogram for the Data /wo Aug') \n",
    "    elif spectrogram_type == 'linear':\n",
    "        audio_spec_noaug = librosa.amplitude_to_db(librosa.stft(audio), np.max) \n",
    "        plt.subplot(4,2,1)\n",
    "        librosa.display.specshow(audio_spec_noaug, y_axis=spectrogram_type) # for mel spectrogram representation\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Linear-freq Power Spectogram for the Data /wo Aug')\n",
    "\n",
    "    display(Audio(data=audio, rate=sample_rate))\n",
    "\n",
    "    #augmentation for visualization\n",
    "    # augmentation_list_format = [noise_flag, crop_freq_time_flag, noise_factor, shift_factor, pitch_factor, speed_rate, time_or_freq_crop_factor, reflection_factor]\n",
    "    audio_aug = main_effect(X, sample_rate=sample_rate, added_shift_factor=added_shift_factor, \n",
    "                            snr_dbs=snr_dbs, crop_factor=0, noise_factor=noise_factor, \n",
    "                            shift_factor=shift_factor, pitch_factor=pitch_factor, speed_rate=speed_rate, duration=duration, decimal=aug)\n",
    "\n",
    "    # visualization for the augmented data\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    \n",
    "    if spectrogram_type == 'mel':\n",
    "        if aug[1]:\n",
    "            audio_spec_aug = rand_cancel(librosa.feature.melspectrogram(y=audio_aug, sr=sample_rate), crop_factor=aug[0]) # for mel spectrogram representation, data crop on mel-frequency domain\n",
    "        else:\n",
    "            audio_aug = rand_cancel(data=audio_aug, crop_factor=aug[0]) # for mel spectrogram representation, data crop on time domain\n",
    "            audio_spec_aug = librosa.feature.melspectrogram(y=audio_aug, sr=sample_rate) # for mel spectrogram representation, data crop on time domain\n",
    "       \n",
    "        audio_spec_aug = librosa.power_to_db(audio_spec_aug, ref=np.max) # for mel spectrogram representation\n",
    "        plt.subplot(4,2,1)\n",
    "        librosa.display.specshow(audio_spec_aug, y_axis='mel') # for mel spectrogram representation\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Mel-freq Power Spectogram for the Data /w Aug')\n",
    "    elif spectrogram_type == 'linear':\n",
    "        audio_spec_aug = librosa.amplitude_to_db(librosa.stft(audio_aug), np.max) # for linear spectrogram representation \n",
    "        plt.subplot(4,2,1)\n",
    "        librosa.display.specshow(audio_spec_aug, y_axis='linear') # for linear spectrogram representation\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title('Linear-freq Power Spectogram for the Data /w Aug')\n",
    "\n",
    "    \n",
    "    display(Audio(data=audio_aug, rate=sample_rate))\n",
    "    \n",
    "def plot_waveform(data, sample_rate):\n",
    "    \"\"\"\n",
    "    visualizes the waveform in time domain, as in amplitudes\n",
    "    meaningful together with the frequency spectrograms\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    librosa.display.waveplot(data, sr=sample_rate, alpha=0.7)\n",
    "    plt.title('Audio Waveform')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b296e990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.938917Z",
     "iopub.status.busy": "2024-09-06T17:42:58.938078Z",
     "iopub.status.idle": "2024-09-06T17:42:58.949715Z",
     "shell.execute_reply": "2024-09-06T17:42:58.948616Z"
    },
    "papermill": {
     "duration": 0.028673,
     "end_time": "2024-09-06T17:42:58.952160",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.923487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmented training and performance evaluation\n",
    "def model_trainer(data, model_name, aug_set, X_train_no_aug, Y_train_no_aug):\n",
    "    \"\"\"\n",
    "    takes in the dataFrame and the related training data from the not augmented model X_train_no_aug & Y_train_no_aug\n",
    "    also takes in a model_name and aug_set\n",
    "    gives out the model, besides the time and accuracy data of preprocessing, training and evaluation\n",
    "    \"\"\"\n",
    "    aug_set[0] = noise_flag\n",
    "    aug_set[1] = crop_freq_time_flag\n",
    "    [noise_factor, shift_factor, pitch_factor, speed_rate, time_or_freq_crop_factor, reflection_factor] = aug_set[2:]\n",
    "            \n",
    "    feature, label, start, end = parser(data, noise_factor=noise_flag, crop_freq=crop_freq_time_flag, snr_dbs=noise_factor,\n",
    "                                                    shift_factor=shift_factor, pitch_factor=pitch_factor, speed_rate=speed_rate,\n",
    "                                                    crop_factor=time_or_freq_crop_factor, added_shift_factor=reflection_factor, decimal = True, aug = True)\n",
    "    \n",
    "    X_train_aug, X_test_aug, Y_train_aug, Y_test_aug = prepare_data(feature, label)\n",
    "\n",
    "    #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "    X_train = np.concatenate((X_train, X_train_aug), axis=0)\n",
    "    Y_train = np.concatenate((Y_train, Y_train_aug), axis=0)\n",
    "\n",
    "    model_aug, train_time_aug = train_model(train = True, model_name = model_name, X_test = X_test, X_train = X_train, Y_test = Y_test, Y_train = Y_train, epochs = 90)\n",
    "    train_result_aug, test_result_aug, eval_time_aug = train_test_accuracy(model_aug, X_train, X_test, Y_train, Y_test)\n",
    "    dataprep_aug = (end-start)/60\n",
    "\n",
    "    print(dataprep_aug)\n",
    "    print(train_time_aug)\n",
    "    print(eval_time_aug)\n",
    "    \n",
    "    return [model_aug, test_result_aug, train_result_aug, dataprep_aug, train_time_aug, eval_time_aug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3980ed63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T17:42:58.980283Z",
     "iopub.status.busy": "2024-09-06T17:42:58.979853Z",
     "iopub.status.idle": "2024-09-06T18:09:41.388375Z",
     "shell.execute_reply": "2024-09-06T18:09:41.386650Z"
    },
    "papermill": {
     "duration": 1602.425699,
     "end_time": "2024-09-06T18:09:41.391153",
     "exception": false,
     "start_time": "2024-09-06T17:42:58.965454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "Epoch 1/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4292 - loss: 1.7193 - val_accuracy: 0.5575 - val_loss: 1.3146\n",
      "Epoch 2/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6171 - loss: 1.1506 - val_accuracy: 0.6051 - val_loss: 1.1452\n",
      "Epoch 3/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6832 - loss: 0.9256 - val_accuracy: 0.6647 - val_loss: 1.0788\n",
      "Epoch 4/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7289 - loss: 0.8271 - val_accuracy: 0.7178 - val_loss: 0.9002\n",
      "Epoch 5/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7592 - loss: 0.7258 - val_accuracy: 0.7371 - val_loss: 0.8741\n",
      "Epoch 6/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7813 - loss: 0.6706 - val_accuracy: 0.7045 - val_loss: 0.9495\n",
      "Epoch 7/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8056 - loss: 0.5837 - val_accuracy: 0.7430 - val_loss: 0.8607\n",
      "Epoch 8/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8153 - loss: 0.5531 - val_accuracy: 0.7609 - val_loss: 0.8283\n",
      "Epoch 9/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8303 - loss: 0.5175 - val_accuracy: 0.7623 - val_loss: 0.7780\n",
      "Epoch 10/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8488 - loss: 0.4566 - val_accuracy: 0.7755 - val_loss: 0.8532\n",
      "Epoch 11/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8636 - loss: 0.4102 - val_accuracy: 0.7545 - val_loss: 0.8923\n",
      "Epoch 12/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8605 - loss: 0.4281 - val_accuracy: 0.7787 - val_loss: 0.7717\n",
      "Epoch 13/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8786 - loss: 0.3625 - val_accuracy: 0.7852 - val_loss: 0.8395\n",
      "Epoch 14/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8813 - loss: 0.3506 - val_accuracy: 0.7907 - val_loss: 0.7769\n",
      "Epoch 15/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8811 - loss: 0.3380 - val_accuracy: 0.7934 - val_loss: 0.8069\n",
      "Epoch 16/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.8908 - loss: 0.3294 - val_accuracy: 0.7948 - val_loss: 0.7796\n",
      "Epoch 17/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8934 - loss: 0.3320 - val_accuracy: 0.8049 - val_loss: 0.7923\n",
      "Epoch 18/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9029 - loss: 0.2924 - val_accuracy: 0.8085 - val_loss: 0.7810\n",
      "Epoch 19/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9141 - loss: 0.2716 - val_accuracy: 0.8126 - val_loss: 0.7737\n",
      "Epoch 20/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9114 - loss: 0.2704 - val_accuracy: 0.8177 - val_loss: 0.8208\n",
      "Epoch 21/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9168 - loss: 0.2497 - val_accuracy: 0.8140 - val_loss: 0.7854\n",
      "Epoch 22/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9155 - loss: 0.2427 - val_accuracy: 0.8204 - val_loss: 0.7882\n",
      "Epoch 23/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9217 - loss: 0.2352 - val_accuracy: 0.7994 - val_loss: 0.8198\n",
      "Epoch 24/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9242 - loss: 0.2344 - val_accuracy: 0.8301 - val_loss: 0.7590\n",
      "Epoch 25/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9360 - loss: 0.1907 - val_accuracy: 0.8172 - val_loss: 0.8037\n",
      "Epoch 26/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9320 - loss: 0.2113 - val_accuracy: 0.8273 - val_loss: 0.7983\n",
      "Epoch 27/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9338 - loss: 0.2006 - val_accuracy: 0.8333 - val_loss: 0.7393\n",
      "Epoch 28/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9366 - loss: 0.1853 - val_accuracy: 0.8218 - val_loss: 0.8040\n",
      "Epoch 29/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9491 - loss: 0.1524 - val_accuracy: 0.8388 - val_loss: 0.7424\n",
      "Epoch 30/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9443 - loss: 0.1630 - val_accuracy: 0.8287 - val_loss: 0.8147\n",
      "Epoch 31/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9447 - loss: 0.1708 - val_accuracy: 0.8351 - val_loss: 0.7770\n",
      "Epoch 32/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9410 - loss: 0.1703 - val_accuracy: 0.8447 - val_loss: 0.7571\n",
      "Epoch 33/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9532 - loss: 0.1414 - val_accuracy: 0.8438 - val_loss: 0.7778\n",
      "Epoch 34/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9489 - loss: 0.1588 - val_accuracy: 0.8452 - val_loss: 0.7843\n",
      "Epoch 35/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9639 - loss: 0.1257 - val_accuracy: 0.8484 - val_loss: 0.7406\n",
      "Epoch 36/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9566 - loss: 0.1276 - val_accuracy: 0.8493 - val_loss: 0.7631\n",
      "Epoch 37/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9600 - loss: 0.1269 - val_accuracy: 0.8227 - val_loss: 0.8952\n",
      "Epoch 38/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9487 - loss: 0.1644 - val_accuracy: 0.8360 - val_loss: 0.8057\n",
      "Epoch 39/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9621 - loss: 0.1270 - val_accuracy: 0.8470 - val_loss: 0.7110\n",
      "Epoch 40/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9665 - loss: 0.1045 - val_accuracy: 0.8470 - val_loss: 0.7497\n",
      "Epoch 41/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9660 - loss: 0.0974 - val_accuracy: 0.8443 - val_loss: 0.7954\n",
      "Epoch 42/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9683 - loss: 0.0929 - val_accuracy: 0.8484 - val_loss: 0.7969\n",
      "Epoch 43/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9697 - loss: 0.0971 - val_accuracy: 0.8516 - val_loss: 0.7795\n",
      "Epoch 44/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9686 - loss: 0.0931 - val_accuracy: 0.8333 - val_loss: 0.8795\n",
      "Epoch 45/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9620 - loss: 0.1142 - val_accuracy: 0.8438 - val_loss: 0.8758\n",
      "Epoch 46/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9671 - loss: 0.1058 - val_accuracy: 0.8585 - val_loss: 0.7507\n",
      "Epoch 47/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9674 - loss: 0.0980 - val_accuracy: 0.8534 - val_loss: 0.8010\n",
      "Epoch 48/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9651 - loss: 0.1005 - val_accuracy: 0.8566 - val_loss: 0.8369\n",
      "Epoch 49/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9702 - loss: 0.0836 - val_accuracy: 0.8406 - val_loss: 0.8614\n",
      "Epoch 50/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9647 - loss: 0.1072 - val_accuracy: 0.8539 - val_loss: 0.7841\n",
      "Epoch 51/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9622 - loss: 0.1102 - val_accuracy: 0.8585 - val_loss: 0.7799\n",
      "Epoch 52/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9774 - loss: 0.0721 - val_accuracy: 0.8552 - val_loss: 0.7827\n",
      "Epoch 53/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9722 - loss: 0.0777 - val_accuracy: 0.8649 - val_loss: 0.7496\n",
      "Epoch 54/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9781 - loss: 0.0688 - val_accuracy: 0.8639 - val_loss: 0.7772\n",
      "Epoch 55/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9777 - loss: 0.0657 - val_accuracy: 0.8566 - val_loss: 0.7855\n",
      "Epoch 56/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9690 - loss: 0.0942 - val_accuracy: 0.8635 - val_loss: 0.8396\n",
      "Epoch 57/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9748 - loss: 0.0772 - val_accuracy: 0.8589 - val_loss: 0.8532\n",
      "Epoch 58/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9773 - loss: 0.0733 - val_accuracy: 0.8658 - val_loss: 0.8159\n",
      "Epoch 59/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9732 - loss: 0.0844 - val_accuracy: 0.8543 - val_loss: 0.8657\n",
      "Epoch 60/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9743 - loss: 0.0732 - val_accuracy: 0.8548 - val_loss: 0.9156\n",
      "Epoch 61/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9793 - loss: 0.0718 - val_accuracy: 0.8580 - val_loss: 0.8565\n",
      "Epoch 62/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9780 - loss: 0.0696 - val_accuracy: 0.8420 - val_loss: 0.9441\n",
      "Epoch 63/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9705 - loss: 0.0881 - val_accuracy: 0.8539 - val_loss: 0.8890\n",
      "Epoch 64/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9732 - loss: 0.0842 - val_accuracy: 0.8520 - val_loss: 0.8378\n",
      "Epoch 65/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9827 - loss: 0.0537 - val_accuracy: 0.8543 - val_loss: 0.8967\n",
      "Epoch 66/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9758 - loss: 0.0680 - val_accuracy: 0.8433 - val_loss: 0.9020\n",
      "Epoch 67/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9738 - loss: 0.0816 - val_accuracy: 0.8575 - val_loss: 0.8913\n",
      "Epoch 68/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9775 - loss: 0.0754 - val_accuracy: 0.8543 - val_loss: 0.9286\n",
      "Epoch 69/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9799 - loss: 0.0588 - val_accuracy: 0.8585 - val_loss: 0.9668\n",
      "Epoch 70/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9795 - loss: 0.0690 - val_accuracy: 0.8607 - val_loss: 0.9169\n",
      "Epoch 71/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9792 - loss: 0.0617 - val_accuracy: 0.8585 - val_loss: 0.8550\n",
      "Epoch 72/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9789 - loss: 0.0617 - val_accuracy: 0.8525 - val_loss: 0.9338\n",
      "Epoch 73/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9756 - loss: 0.0746 - val_accuracy: 0.8516 - val_loss: 0.8843\n",
      "Epoch 74/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9773 - loss: 0.0633 - val_accuracy: 0.8644 - val_loss: 0.9258\n",
      "Epoch 75/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9768 - loss: 0.0619 - val_accuracy: 0.8630 - val_loss: 0.8442\n",
      "Epoch 76/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9819 - loss: 0.0515 - val_accuracy: 0.8566 - val_loss: 0.8926\n",
      "Epoch 77/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9822 - loss: 0.0474 - val_accuracy: 0.8626 - val_loss: 0.8282\n",
      "Epoch 78/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9847 - loss: 0.0423 - val_accuracy: 0.8781 - val_loss: 0.8054\n",
      "Epoch 79/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9825 - loss: 0.0522 - val_accuracy: 0.8690 - val_loss: 0.8763\n",
      "Epoch 80/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9881 - loss: 0.0417 - val_accuracy: 0.8685 - val_loss: 0.8191\n",
      "Epoch 81/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.9819 - loss: 0.0516 - val_accuracy: 0.8548 - val_loss: 0.8994\n",
      "Epoch 82/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9814 - loss: 0.0542 - val_accuracy: 0.8566 - val_loss: 0.9459\n",
      "Epoch 83/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9780 - loss: 0.0634 - val_accuracy: 0.8635 - val_loss: 0.8752\n",
      "Epoch 84/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9781 - loss: 0.0648 - val_accuracy: 0.8681 - val_loss: 0.9183\n",
      "Epoch 85/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9824 - loss: 0.0512 - val_accuracy: 0.8644 - val_loss: 0.8838\n",
      "Epoch 86/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9833 - loss: 0.0480 - val_accuracy: 0.8694 - val_loss: 0.8969\n",
      "Epoch 87/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9883 - loss: 0.0345 - val_accuracy: 0.8594 - val_loss: 0.8914\n",
      "Epoch 88/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9852 - loss: 0.0468 - val_accuracy: 0.8676 - val_loss: 0.8885\n",
      "Epoch 89/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9850 - loss: 0.0396 - val_accuracy: 0.8539 - val_loss: 0.9456\n",
      "Epoch 90/90\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9833 - loss: 0.0581 - val_accuracy: 0.8607 - val_loss: 0.9689\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8495 - loss: 0.9486\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9840 - loss: 0.0480\n",
      "19.365832964579266\n",
      "7.272676821549734\n",
      "0.06666823625564575\n"
     ]
    }
   ],
   "source": [
    "# read the original dataset\n",
    "df = pd.read_csv(\"/kaggle/input/urbansound8k/UrbanSound8K.csv\")\n",
    "\n",
    "# no augmentation, base model\n",
    "feature, label, start, end = parser(df, noise_factor=0, crop_factor=0, shift_factor=0, pitch_factor=0, speed_rate=1, decimal = True, aug = False)\n",
    "X_train, X_test, Y_train, Y_test = prepare_data(feature, label)\n",
    "\n",
    "model_noaug, train_time_noaug = train_model(train = True, model_name = \"Original_Model\", X_test = X_test, X_train = X_train, Y_test = Y_test, Y_train = Y_train, epochs = 90)\n",
    "train_result_noaug, test_result_noaug, eval_time_noaug = train_test_accuracy(model_noaug, X_train, X_test, Y_train, Y_test)\n",
    "time_elapsed_no_aug = (end-start)/60\n",
    "\n",
    "print(time_elapsed_no_aug)\n",
    "print(train_time_noaug)\n",
    "print(eval_time_noaug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3b5d655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:42.842028Z",
     "iopub.status.busy": "2024-09-06T18:09:42.841069Z",
     "iopub.status.idle": "2024-09-06T18:09:42.848090Z",
     "shell.execute_reply": "2024-09-06T18:09:42.847003Z"
    },
    "papermill": {
     "duration": 0.692104,
     "end_time": "2024-09-06T18:09:42.850531",
     "exception": false,
     "start_time": "2024-09-06T18:09:42.158427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_crop_control_list = [[0,1,0.05,0,0,0,1], [0,1,0.1,0,0,0,1], [0,1,0.2,0,0,0,1], [0,1,0.5,0,0,0,1]]\n",
    "# reflect_control_list = [[0,1,0,0.05,0,0,1], [0,1,0,0.1,0,0,1], [0,1,0,0.2,0,0,1]]\n",
    "\n",
    "# sample_list = [data_crop_control_list, reflect_control_list]\n",
    "# alt_train_acc, alt_valid_acc, alt_dataprep_time_listed, alt_eval_time_listed = [],[],[],[]\n",
    "\n",
    "# for control in sample_list:\n",
    "#     for sample in control:\n",
    "\n",
    "#         # separating the data into features and labels for further operation\n",
    "#         feature, label, start, end = parser(df, noise_factor=sample[0], snr_dbs=sample[1], crop_factor=sample[2], added_shift_factor=sample[3], shift_factor=sample[4], pitch_factor=sample[5], speed_rate=sample[6], decimal = True, aug = True)\n",
    "\n",
    "#         # preparation of the train and test data\n",
    "#         X_train, X_test, Y_train, Y_test = prepare_data(feature, label)\n",
    "\n",
    "#         # calling the existing model trained without any augmentation method utilized\n",
    "#         model = train_model(train = False, model_name = \"Original_Model.keras\")\n",
    "\n",
    "#         # accuracy attainment\n",
    "#         train_result, test_result, eval_time = train_test_accuracy(model, X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "#         time_elapsed = (end-start)/60\n",
    "        \n",
    "#         print(time_elapsed)\n",
    "#         print(eval_time)\n",
    "\n",
    "#         alt_train_acc.append(train_result)\n",
    "#         alt_valid_acc.append(test_result)\n",
    "#         alt_dataprep_time_listed.append(time_elapsed)\n",
    "#         alt_eval_time_listed.append(eval_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f579f147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:44.224326Z",
     "iopub.status.busy": "2024-09-06T18:09:44.223916Z",
     "iopub.status.idle": "2024-09-06T18:09:44.229621Z",
     "shell.execute_reply": "2024-09-06T18:09:44.228420Z"
    },
    "papermill": {
     "duration": 0.684028,
     "end_time": "2024-09-06T18:09:44.232166",
     "exception": false,
     "start_time": "2024-09-06T18:09:43.548138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # noise augmentation through the extended dataset, SNR=20dB\n",
    "# feature, label, start, end = parser(df, noise_factor=1, snr_dbs=12, shift_factor=0, pitch_factor=0, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_noised, X_test_noised, Y_train_noised, Y_test_noised = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train1 = np.concatenate((X_train, X_train_noised), axis=0)\n",
    "# Y_train1 = np.concatenate((Y_train, Y_train_noised), axis=0)\n",
    "\n",
    "# model_noise, train_time_noise = train_model(train = True, model_name = \"Model_Noise\", X_test = X_test, X_train = X_train1, Y_test = Y_test, Y_train = Y_train1, epochs = 90)\n",
    "# train_result_noiseaug, test_result_noiseaug, eval_time_noiseaug = train_test_accuracy(model_noise, X_train1, X_test, Y_train1, Y_test)\n",
    "# time_elapsed_noise_aug = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_noise_aug)\n",
    "# print(train_time_noise)\n",
    "# print(eval_time_noiseaug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "775b9ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:45.661680Z",
     "iopub.status.busy": "2024-09-06T18:09:45.661254Z",
     "iopub.status.idle": "2024-09-06T18:09:45.667484Z",
     "shell.execute_reply": "2024-09-06T18:09:45.666251Z"
    },
    "papermill": {
     "duration": 0.68874,
     "end_time": "2024-09-06T18:09:45.669988",
     "exception": false,
     "start_time": "2024-09-06T18:09:44.981248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # noise augmentation through the extended dataset, SNR=20dB\n",
    "# feature, label, start, end = parser(df, noise_factor=1, snr_dbs=20, shift_factor=0, pitch_factor=0, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_noised2, X_test_noised2, Y_train_noised2, Y_test_noised2 = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train11 = np.concatenate((X_train, X_train_noised2), axis=0)\n",
    "# Y_train11 = np.concatenate((Y_train, Y_train_noised2), axis=0)\n",
    "\n",
    "# model_noise2, train_time_noise2 = train_model(train = True, model_name = \"Model_Noise2\", X_test = X_test, X_train = X_train11, Y_test = Y_test, Y_train = Y_train11, epochs = 90)\n",
    "# train_result_noiseaug2, test_result_noiseaug2, eval_time_noiseaug2 = train_test_accuracy(model_noise2, X_train11, X_test, Y_train11, Y_test)\n",
    "# time_elapsed_noise_aug2 = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_noise_aug2)\n",
    "# print(train_time_noise2)\n",
    "# print(eval_time_noiseaug2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4ccc15e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:47.059171Z",
     "iopub.status.busy": "2024-09-06T18:09:47.057983Z",
     "iopub.status.idle": "2024-09-06T18:09:47.064546Z",
     "shell.execute_reply": "2024-09-06T18:09:47.063116Z"
    },
    "papermill": {
     "duration": 0.713141,
     "end_time": "2024-09-06T18:09:47.067092",
     "exception": false,
     "start_time": "2024-09-06T18:09:46.353951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # speed augmentation through the extended dataset, speed_rate=1.1\n",
    "# feature, label, start, end = parser(df, noise_factor=0, snr_dbs=1, shift_factor=0, pitch_factor=0, speed_rate=1.1, decimal = True, aug = True)\n",
    "# X_train_sped, X_test_sped, Y_train_sped, Y_test_sped = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train2 = np.concatenate((X_train, X_train_sped), axis=0)\n",
    "# Y_train2 = np.concatenate((Y_train, Y_train_sped), axis=0)\n",
    "\n",
    "# model_speed, train_time_sped = train_model(train = True, model_name = \"Model_Speed\", X_test = X_test, X_train = X_train2, Y_test = Y_test, Y_train = Y_train2, epochs = 90)\n",
    "# train_result_speed, test_result_speed, eval_time_sped = train_test_accuracy(model_speed, X_train2, X_test, Y_train2, Y_test)\n",
    "# time_elapsed_speed_aug = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_speed_aug)\n",
    "# print(train_time_sped)\n",
    "# print(eval_time_sped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccda2d4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:48.492643Z",
     "iopub.status.busy": "2024-09-06T18:09:48.492179Z",
     "iopub.status.idle": "2024-09-06T18:09:48.498575Z",
     "shell.execute_reply": "2024-09-06T18:09:48.497006Z"
    },
    "papermill": {
     "duration": 0.689888,
     "end_time": "2024-09-06T18:09:48.501593",
     "exception": false,
     "start_time": "2024-09-06T18:09:47.811705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # pitch augmentation through the extended dataset, p_fact=0.1ss\n",
    "# feature, label, start, end = parser(df, noise_factor=0, snr_dbs=1, shift_factor=0, pitch_factor=0.1, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_pitched1, X_test_pitched1, Y_train_pitched1, Y_test_pitched1 = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train3 = np.concatenate((X_train, X_train_pitched1), axis=0)\n",
    "# Y_train3 = np.concatenate((Y_train, Y_train_pitched1), axis=0)\n",
    "\n",
    "# model_pitch, train_time_pitch = train_model(train = True, model_name = \"Model_Pitch1\", X_test = X_test, X_train = X_train3, Y_test = Y_test, Y_train = Y_train3, epochs = 90)\n",
    "# train_result_pitch, test_result_pitch, eval_time_pitch = train_test_accuracy(model_pitch, X_train3, X_test, Y_train3, Y_test)\n",
    "# time_elapsed_pitch_aug = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_pitch_aug)\n",
    "# print(train_time_pitch)\n",
    "# print(eval_time_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a595cbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:49.854825Z",
     "iopub.status.busy": "2024-09-06T18:09:49.854213Z",
     "iopub.status.idle": "2024-09-06T18:09:49.861706Z",
     "shell.execute_reply": "2024-09-06T18:09:49.860486Z"
    },
    "papermill": {
     "duration": 0.684955,
     "end_time": "2024-09-06T18:09:49.864079",
     "exception": false,
     "start_time": "2024-09-06T18:09:49.179124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # pitch augmentation through the extended dataset, p_fact=0.25\n",
    "# feature, label, start, end = parser(df, noise_factor=0, snr_dbs=1, shift_factor=0, pitch_factor=0.25, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_pitched2, X_test_pitched2, Y_train_pitched2, Y_test_pitched2 = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train4 = np.concatenate((X_train, X_train_pitched2), axis=0)\n",
    "# Y_train4 = np.concatenate((Y_train, Y_train_pitched2), axis=0)\n",
    "\n",
    "# model_pitch2, train_time_pitch2 = train_model(train = True, model_name = \"Model_Pitch2\", X_test = X_test, X_train = X_train4, Y_test = Y_test, Y_train = Y_train4, epochs = 90)\n",
    "# train_result_pitch2, test_result_pitch2, eval_time_pitch2 = train_test_accuracy(model_pitch2, X_train4, X_test, Y_train4, Y_test)\n",
    "# time_elapsed_pitch_aug2 = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_pitch_aug2)\n",
    "# print(train_time_pitch2)\n",
    "# print(eval_time_pitch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11a09752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:51.289647Z",
     "iopub.status.busy": "2024-09-06T18:09:51.288731Z",
     "iopub.status.idle": "2024-09-06T18:09:51.294988Z",
     "shell.execute_reply": "2024-09-06T18:09:51.293835Z"
    },
    "papermill": {
     "duration": 0.685556,
     "end_time": "2024-09-06T18:09:51.297460",
     "exception": false,
     "start_time": "2024-09-06T18:09:50.611904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # pitch augmentation through the extended dataset, p_fact=0.5\n",
    "# feature, label, start, end = parser(df, noise_factor=0, snr_dbs=1, shift_factor=0, pitch_factor=0.5, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_pitched3, X_test_pitched3, Y_train_pitched3, Y_test_pitched3 = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train5 = np.concatenate((X_train, X_train_pitched3), axis=0)\n",
    "# Y_train5 = np.concatenate((Y_train, Y_train_pitched3), axis=0)\n",
    "\n",
    "# model_pitch3, train_time_pitch3 = train_model(train = True, model_name = \"Model_Pitch3\", X_test = X_test, X_train = X_train5, Y_test = Y_test, Y_train = Y_train5, epochs = 90)\n",
    "# train_result_pitch3, test_result_pitch3, eval_time_pitch3 = train_test_accuracy(model_pitch3, X_train5, X_test, Y_train5, Y_test)\n",
    "# time_elapsed_pitch_aug3 = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_pitch_aug3)\n",
    "# print(train_time_pitch3)\n",
    "# print(eval_time_pitch3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e915a7a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:52.676773Z",
     "iopub.status.busy": "2024-09-06T18:09:52.676100Z",
     "iopub.status.idle": "2024-09-06T18:09:52.682238Z",
     "shell.execute_reply": "2024-09-06T18:09:52.681052Z"
    },
    "papermill": {
     "duration": 0.697627,
     "end_time": "2024-09-06T18:09:52.684775",
     "exception": false,
     "start_time": "2024-09-06T18:09:51.987148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # crop augmentation through the extended dataset, crop_factor=0.05\n",
    "# feature, label, start, end = parser(df, noise_factor=0, crop_factor=0.05, snr_dbs=1, shift_factor=0, pitch_factor=0, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_crop1, X_test_crop1, Y_train_crop1, Y_test_crop1 = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train6 = np.concatenate((X_train, X_train_crop1), axis=0)\n",
    "# Y_train6 = np.concatenate((Y_train, Y_train_crop1), axis=0)\n",
    "\n",
    "# model_crop1, train_time_crop1 = train_model(train = True, model_name = \"Model_Crop1\", X_test = X_test, X_train = X_train6, Y_test = Y_test, Y_train = Y_train6, epochs = 90)\n",
    "# train_result_crop1, test_result_crop1, eval_time_crop1 = train_test_accuracy(model_crop1, X_train6, X_test, Y_train6, Y_test)\n",
    "# time_elapsed_crop1_aug = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_crop1_aug)\n",
    "# print(train_time_crop1)\n",
    "# print(eval_time_crop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "101b1308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:54.120335Z",
     "iopub.status.busy": "2024-09-06T18:09:54.119299Z",
     "iopub.status.idle": "2024-09-06T18:09:54.126015Z",
     "shell.execute_reply": "2024-09-06T18:09:54.124623Z"
    },
    "papermill": {
     "duration": 0.694358,
     "end_time": "2024-09-06T18:09:54.128512",
     "exception": false,
     "start_time": "2024-09-06T18:09:53.434154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # crop augmentation through the extended dataset, crop_factor=0.1\n",
    "# feature, label, start, end = parser(df, noise_factor=0, crop_factor=0.1, snr_dbs=1, shift_factor=0, pitch_factor=0, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_crop2, X_test_crop2, Y_train_crop2, Y_test_crop2 = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train7 = np.concatenate((X_train, X_train_crop2), axis=0)\n",
    "# Y_train7 = np.concatenate((Y_train, Y_train_crop2), axis=0)\n",
    "\n",
    "# model_crop2, train_time_crop2 = train_model(train = True, model_name = \"Model_Crop2\", X_test = X_test, X_train = X_train7, Y_test = Y_test, Y_train = Y_train7, epochs = 90)\n",
    "# train_result_crop2, test_result_crop2, eval_time_crop2 = train_test_accuracy(model_crop2, X_train7, X_test, Y_train7, Y_test)\n",
    "# time_elapsed_crop2_aug = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_crop2_aug)\n",
    "# print(train_time_crop2)\n",
    "# print(eval_time_crop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1008133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:55.482492Z",
     "iopub.status.busy": "2024-09-06T18:09:55.482002Z",
     "iopub.status.idle": "2024-09-06T18:09:55.488372Z",
     "shell.execute_reply": "2024-09-06T18:09:55.487066Z"
    },
    "papermill": {
     "duration": 0.684749,
     "end_time": "2024-09-06T18:09:55.490899",
     "exception": false,
     "start_time": "2024-09-06T18:09:54.806150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # reflection augmentation through the extended dataset, refl_factor=0.05\n",
    "# feature, label, start, end = parser(df, noise_factor=0, added_shift_factor=0.05, snr_dbs=1, shift_factor=0, pitch_factor=0, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_refl, X_test_refl, Y_train_refl, Y_test_refl = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train8 = np.concatenate((X_train, X_train_refl), axis=0)\n",
    "# Y_train8 = np.concatenate((Y_train, Y_train_refl), axis=0)\n",
    "\n",
    "# model_refl1, train_time_refl1 = train_model(train = True, model_name = \"Model_Refl1\", X_test = X_test, X_train = X_train8, Y_test = Y_test, Y_train = Y_train8, epochs = 90)\n",
    "# train_result_refl1, test_result_refl1, eval_time_refl1 = train_test_accuracy(model_refl1, X_train8, X_test, Y_train8, Y_test)\n",
    "# time_elapsed_refl1_aug = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_refl1_aug)\n",
    "# print(train_time_refl1)\n",
    "# print(eval_time_refl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68e35df3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:56.954427Z",
     "iopub.status.busy": "2024-09-06T18:09:56.954015Z",
     "iopub.status.idle": "2024-09-06T18:09:56.960242Z",
     "shell.execute_reply": "2024-09-06T18:09:56.958988Z"
    },
    "papermill": {
     "duration": 0.722446,
     "end_time": "2024-09-06T18:09:56.962721",
     "exception": false,
     "start_time": "2024-09-06T18:09:56.240275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # reflection augmentation through the extended dataset, refl_factor=0.1\n",
    "# feature, label, start, end = parser(df, noise_factor=0, added_shift_factor=0.1, snr_dbs=1, shift_factor=0, pitch_factor=0, speed_rate=1, decimal = True, aug = True)\n",
    "# X_train_refl2, X_test_refl2, Y_train_refl2, Y_test_refl2 = prepare_data(feature, label)\n",
    "\n",
    "# #extension for the training, p.s. validation should stay the same as it was in the no augmentation case for comparison\n",
    "# X_train9 = np.concatenate((X_train, X_train_refl2), axis=0)\n",
    "# Y_train9 = np.concatenate((Y_train, Y_train_refl2), axis=0)\n",
    "\n",
    "# model_refl2, train_time_refl2 = train_model(train = True, model_name = \"Model_Refl2\", X_test = X_test, X_train = X_train9, Y_test = Y_test, Y_train = Y_train9, epochs = 90)\n",
    "# train_result_refl2, test_result_refl2, eval_time_refl2 = train_test_accuracy(model_refl2, X_train9, X_test, Y_train9, Y_test)\n",
    "# time_elapsed_refl2_aug = (end-start)/60\n",
    "\n",
    "# print(time_elapsed_refl2_aug)\n",
    "# print(train_time_refl2)\n",
    "# print(eval_time_refl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "342141a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:58.319002Z",
     "iopub.status.busy": "2024-09-06T18:09:58.317734Z",
     "iopub.status.idle": "2024-09-06T18:09:58.324833Z",
     "shell.execute_reply": "2024-09-06T18:09:58.323669Z"
    },
    "papermill": {
     "duration": 0.688875,
     "end_time": "2024-09-06T18:09:58.327371",
     "exception": false,
     "start_time": "2024-09-06T18:09:57.638496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # sample = [noise_flag, noise_factor, shift_factor, pitch_factor, speed_factor] below\n",
    "# noise_control_list = [[1,0,0,0,1], [1,5,0,0,1], [1,10,0,0,1], [1,15,0,0,1], [1,20,0,0,1]] \n",
    "# shift_control_list = [[0,1,0.05,0,1], [0,1,0.15,0,1], [0,1,0.35,0,1]]\n",
    "# pitch_control_list = [[0,1,0,0.1,1], [0,1,0,0.25,1], [0,1,0,0.5,1], [0,1,0,1,1]] \n",
    "# time_stretch_control_list = [[0,1,0,0,.90], [0,1,0,0,1.05], [0,1,0,0,1.10]]\n",
    "\n",
    "\n",
    "# sample_list = [noise_control_list, shift_control_list, pitch_control_list, time_stretch_control_list]\n",
    "\n",
    "# train_acc, valid_acc, dataprep_time_listed, eval_time_listed = [],[],[],[]\n",
    "\n",
    "# for control in sample_list:\n",
    "#     for sample in control:\n",
    "\n",
    "#         # separating the data into features and labels for further operation\n",
    "#         feature, label, start, end = parser(df, noise_factor=sample[0], snr_dbs=sample[1], shift_factor=sample[2], pitch_factor=sample[3], speed_rate=sample[4], decimal = True, aug = True)\n",
    "\n",
    "#         # preparation of the train and test data\n",
    "#         X_train, X_test, Y_train, Y_test = prepare_data(feature, label)\n",
    "\n",
    "#         # calling the existing model trained without any augmentation method utilized\n",
    "#         model = train_model(train = False, model_name = \"Original_Model.keras\")\n",
    "\n",
    "#         # accuracy attainment\n",
    "#         train_result, test_result, eval_time = train_test_accuracy(model, X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "#         time_elapsed = (end-start)/60\n",
    "#         print(time_elapsed)\n",
    "#         print(eval_time)\n",
    "\n",
    "#         train_acc.append(train_result)\n",
    "#         valid_acc.append(test_result)\n",
    "#         dataprep_time_listed.append(time_elapsed)\n",
    "#         eval_time_listed.append(eval_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fe0b3f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:09:59.761885Z",
     "iopub.status.busy": "2024-09-06T18:09:59.760652Z",
     "iopub.status.idle": "2024-09-06T18:09:59.767863Z",
     "shell.execute_reply": "2024-09-06T18:09:59.766766Z"
    },
    "papermill": {
     "duration": 0.693143,
     "end_time": "2024-09-06T18:09:59.770309",
     "exception": false,
     "start_time": "2024-09-06T18:09:59.077166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # alternative data augmentation methods, inspired by more complex methods and possible scenarios in real life\n",
    "# # sample = [noise_flag, noise_factor, crop_factor, added_shift_factor, shift_factor, pitch_factor, speed_factor] below\n",
    "# data_crop_control_list = [[0,1,0.05,0,0,0,1], [0,1,0.1,0,0,0,1], [0,1,0.2,0,0,0,1], [0,1,0.5,0,0,0,1]]\n",
    "# reflect_control_list = [[0,1,0,0.05,0,0,1], [0,1,0,0.1,0,0,1], [0,1,0,0.2,0,0,1], [0,1,0,0.5,0,0,1]]\n",
    "\n",
    "# sample_list = [data_crop_control_list, reflect_control_list]\n",
    "# alt_train_acc, alt_valid_acc, alt_dataprep_time_listed, alt_eval_time_listed = [],[],[],[]\n",
    "\n",
    "# for control in sample_list:\n",
    "#     for sample in control:\n",
    "\n",
    "#         # separating the data into features and labels for further operation\n",
    "#         feature, label, start, end = parser(df, noise_factor=sample[0], snr_dbs=sample[1], crop_factor=sample[2], added_shift_factor=sample[3], shift_factor=sample[4], pitch_factor=sample[5], speed_rate=sample[6], decimal = True, aug = True)\n",
    "\n",
    "#         # preparation of the train and test data\n",
    "#         X_train, X_test, Y_train, Y_test = prepare_data(feature, label)\n",
    "\n",
    "#         # calling the existing model trained without any augmentation method utilized\n",
    "#         model = train_model(train = False, model_name = \"Original_Model.keras\")\n",
    "\n",
    "#         # accuracy attainment\n",
    "#         train_result, test_result, eval_time = train_test_accuracy(model, X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "#         time_elapsed = (end-start)/60\n",
    "#         print(time_elapsed)\n",
    "#         print(eval_time)\n",
    "\n",
    "#         alt_train_acc.append(train_result)\n",
    "#         alt_valid_acc.append(test_result)\n",
    "#         alt_dataprep_time_listed.append(time_elapsed)\n",
    "#         alt_eval_time_listed.append(eval_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07d2e246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:10:01.125329Z",
     "iopub.status.busy": "2024-09-06T18:10:01.124895Z",
     "iopub.status.idle": "2024-09-06T18:10:01.130796Z",
     "shell.execute_reply": "2024-09-06T18:10:01.129621Z"
    },
    "papermill": {
     "duration": 0.690466,
     "end_time": "2024-09-06T18:10:01.133042",
     "exception": false,
     "start_time": "2024-09-06T18:10:00.442576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_results_dict = {\n",
    "#     'Samples':['NoAugmentation', \n",
    "#                 'Noise, SNR=0dB', 'Noise, SNR=5dB', 'Noise, SNR=10dB', 'Noise, SNR=15dB', 'Noise, SNR=20dB',\n",
    "#                 'Shifted, 5%', 'Shifted, 15%', 'Shifted, 35%',\n",
    "#                 'Pitch Changed, 0.1semiNote', 'Pitch Changed, 0.25semiNote', 'Pitch Changed, 0.5semiNote', 'Pitch Changed, 1semiNote',\n",
    "#                 'Time-Stretched, -10%', 'Time-Stretched, +5%', 'Time-Stretched, +10%'],\n",
    "#     'Training Accuracy': [train_result_noaug] + train_acc,\n",
    "#     'Validation Accuracy': [test_result_noaug] + valid_acc,\n",
    "#     'Data Creation Time': [time_elapsed_no_aug] + dataprep_time_listed,\n",
    "#     'Evaluation Time': [eval_time_noaug] + eval_time_listed\n",
    "# }\n",
    "# test_results = pd.DataFrame(test_results_dict)\n",
    "# test_results.set_index(\"Samples\")\n",
    "\n",
    "# print(test_results)\n",
    "# test_results.to_csv(\"Efficient_Augmentation_Selection_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd5132e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:10:02.558762Z",
     "iopub.status.busy": "2024-09-06T18:10:02.558108Z",
     "iopub.status.idle": "2024-09-06T18:10:02.569801Z",
     "shell.execute_reply": "2024-09-06T18:10:02.568657Z"
    },
    "papermill": {
     "duration": 0.688162,
     "end_time": "2024-09-06T18:10:02.572159",
     "exception": false,
     "start_time": "2024-09-06T18:10:01.883997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augmentation parameter declaration for testing purposes\n",
    "# augmentation_list_format = [noise_flag, crop_freq_time_flag, noise_factor, shift_factor, pitch_factor, speed_rate, time_or_freq_crop_factor, reflection_factor]\n",
    "# crop_freq_time_flag=1 for data cropping in freq domain; crop_freq_time_flag=0 for data cropping in time domain\n",
    "# each type of augmentation has its first value element as the index in the base augmentation list\n",
    "\n",
    "augmentation_dict = {}\n",
    "augmentation_dict['noise_factor'] = [2, 0, 5, 10, 12, 15, 20]\n",
    "augmentation_dict['shift_factor'] = [3, 0.05, 0.15, 0.35] # [0,1] interval\n",
    "augmentation_dict['pitch_factor'] = [4, 0.05, 0.10, 0.25, 0.50, 1]\n",
    "augmentation_dict['speed_rate'] = [5, 0.90, 0.95, 1.1]\n",
    "augmentation_dict['time_crop_factor'] = [6, 0.05, 0.10, 0.20, 0.50] # [0,1] interval\n",
    "augmentation_dict['freq_crop_factor'] = [6, 0.05, 0.10, 0.20, 0.50] # [0,1] interval\n",
    "augmentation_dict['reflection_factor'] = [7,0.05, 0.10, 0.20, 0.50] # [0,1] interval\n",
    "base_augmentation_list = [0, 1, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "# to ease the creation of the index list for the .csv file\n",
    "def factor_percentage(factor):\n",
    "    \"\"\"\n",
    "    percentage calculator for factors in the [0,2] interval\n",
    "    \"\"\"\n",
    "    if factor >=1:\n",
    "        return f\"{(factor-1)*100:.2f}\" + '%'\n",
    "    else:\n",
    "        return f\"{(factor-1)*100:.2f}\" + '%'\n",
    "\n",
    "def pos_factor_percentage(factor):\n",
    "    \"\"\"\n",
    "    percentage calculator for factors in the [0,1] interval\n",
    "    \"\"\"\n",
    "    return f\"{factor*100:.2f}\" + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e8edaf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T18:10:03.931730Z",
     "iopub.status.busy": "2024-09-06T18:10:03.931286Z",
     "iopub.status.idle": "2024-09-07T04:04:05.859844Z",
     "shell.execute_reply": "2024-09-07T04:04:05.857383Z"
    },
    "papermill": {
     "duration": 35642.61136,
     "end_time": "2024-09-07T04:04:05.862889",
     "exception": false,
     "start_time": "2024-09-06T18:10:03.251529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4338 - loss: 4.5285\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5273 - loss: 3.4099\n",
      "19.2798858722051\n",
      "0.08683515389760335\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6643 - loss: 2.4638\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7922 - loss: 1.1903\n",
      "18.23232503334681\n",
      "0.09269158045450847\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7852 - loss: 1.4810\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9325 - loss: 0.3547\n",
      "18.17495164871216\n",
      "0.07478380997975667\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8111 - loss: 1.2894\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9512 - loss: 0.2380\n",
      "17.993691289424895\n",
      "0.08329659303029378\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8324 - loss: 1.0795\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.1277\n",
      "18.00543478727341\n",
      "0.0673388401667277\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8499 - loss: 0.9641\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9810 - loss: 0.0570\n",
      "17.902086353302003\n",
      "0.06975106398264568\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8500 - loss: 0.9489\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9833 - loss: 0.0484\n",
      "17.9242533882459\n",
      "0.07622287670771281\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.9480\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0482\n",
      "17.9371217250824\n",
      "0.08157915671666463\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8507 - loss: 0.9478\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.0483\n",
      "17.84553683201472\n",
      "0.07341945171356201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 1.1242\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.1890\n",
      "26.663376911481222\n",
      "0.07215323448181152\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8225 - loss: 1.1379\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9381 - loss: 0.2074\n",
      "26.436572468280794\n",
      "0.06604110399881999\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7929 - loss: 1.2611\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8863 - loss: 0.4752\n",
      "26.55904163122177\n",
      "0.07878514528274536\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7300 - loss: 1.7191\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7989 - loss: 1.0448\n",
      "26.625990943113962\n",
      "0.0693751056989034\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6310 - loss: 2.5166\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6888 - loss: 2.1294\n",
      "26.88060517311096\n",
      "0.06959844827651977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1470\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1226\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1692\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8136 - loss: 1.1508\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9415 - loss: 0.2195\n",
      "26.73509026368459\n",
      "0.0685434341430664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1393\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1161\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1603\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8042 - loss: 1.1504\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9360 - loss: 0.2344\n",
      "26.39985745747884\n",
      "0.06792409420013427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1943\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=2005\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1203\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1003\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1385\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8177 - loss: 1.1025\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.2068\n",
      "25.383476308981578\n",
      "0.06922105153401693\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 0.9425\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0588\n",
      "17.931534508864086\n",
      "0.06961446603139242\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8479 - loss: 0.9565\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.0868\n",
      "18.00435386101405\n",
      "0.07411026159922282\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8530 - loss: 0.9488\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9649 - loss: 0.1269\n",
      "18.15422537724177\n",
      "0.0755895733833313\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 1.0883\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.3829\n",
      "18.230944649378458\n",
      "0.06980943282445272\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8232 - loss: 1.1750\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.2688\n",
      "18.021890449523926\n",
      "0.06898945569992065\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7749 - loss: 1.5176\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8979 - loss: 0.6738\n",
      "17.936106606324515\n",
      "0.07077635526657104\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7303 - loss: 2.0680\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8297 - loss: 1.2494\n",
      "17.980990946292877\n",
      "0.07143126726150513\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6324 - loss: 3.1738\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7498 - loss: 2.2313\n",
      "17.907457701365153\n",
      "0.0678564190864563\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7609 - loss: 1.6456\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8796 - loss: 0.7574\n",
      "18.079388610521953\n",
      "0.09069608847300212\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7974 - loss: 1.3641\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9090 - loss: 0.5650\n",
      "18.08073336283366\n",
      "0.06538431644439698\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8064 - loss: 1.2572\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.4172\n",
      "18.199667032559713\n",
      "0.06914257605870565\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8113 - loss: 1.2115\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9373 - loss: 0.2862\n",
      "18.237762248516084\n",
      "0.0705688198407491\n",
      "29 29\n"
     ]
    }
   ],
   "source": [
    "# accuracy testing per modified augmentation list, which has only one value changed at a time\n",
    "# augmentation_list_format = [noise_flag, crop_freq_time_flag, noise_factor, shift_factor, pitch_factor, speed_rate, time_or_freq_crop_factor, reflection_factor]\n",
    "# crop_freq_time_flag=1 for data cropping in freq domain; crop_freq_time_flag=0 for data cropping in time domain\n",
    "# each type of augmentation has its first value element as the index in the base augmentation list\n",
    "\n",
    "validation_acc_list, train_acc_list, dataprep_time_list, eval_time_list = [],[],[],[]\n",
    "# list for final dataFrame indices\n",
    "samples_list = []\n",
    "test_counter = 0\n",
    "for aug_method in augmentation_dict.keys():\n",
    "    aug_idx = augmentation_dict[aug_method][0]\n",
    "    dummy_idx = 0\n",
    "    for aug_value in augmentation_dict[aug_method]:\n",
    "        if dummy_idx != 0:\n",
    "            test_counter += 1\n",
    "            modified_augmentation_list = base_augmentation_list.copy()\n",
    "            modified_augmentation_list[aug_idx] = aug_value\n",
    "            \n",
    "            noise_flag = 1 if (aug_method == 'noise_factor') else 0\n",
    "            crop_freq_time_flag = 0 if (aug_method == 'time_crop_factor') else 1\n",
    "            modified_augmentation_list[0] = noise_flag\n",
    "            modified_augmentation_list[1] = crop_freq_time_flag\n",
    "            [noise_factor, shift_factor, pitch_factor, speed_rate, time_or_freq_crop_factor, reflection_factor] = modified_augmentation_list[2:]\n",
    "            \n",
    "            \n",
    "            # data preparation and testing\n",
    "            # extract the feature and label arrays\n",
    "            feature, label, start, end = parser(df, noise_factor=noise_flag, crop_freq=crop_freq_time_flag, snr_dbs=noise_factor,\n",
    "                                                    shift_factor=shift_factor, pitch_factor=pitch_factor, speed_rate=speed_rate,\n",
    "                                                    crop_factor=time_or_freq_crop_factor, added_shift_factor=reflection_factor, decimal = True, aug = True)\n",
    "\n",
    "            # prepare the train and test data\n",
    "            X_train, X_test, Y_train, Y_test = prepare_data(feature, label)\n",
    " \n",
    "            #  call the not_augmented model for testing\n",
    "            model = train_model(train = False, model_name = \"Original_Model.keras\")\n",
    "\n",
    "            # attain the accuracy results\n",
    "            train_result, test_result, eval_time = train_test_accuracy(model, X_train, X_test, Y_train, Y_test)\n",
    "            \n",
    "            #show the time elapsed for further analysis\n",
    "            dataprep_time = (end-start)/60\n",
    "            print(dataprep_time)\n",
    "            print(eval_time)\n",
    "\n",
    "            # accrue the data\n",
    "            validation_acc_list.append(test_result)\n",
    "            train_acc_list.append(train_result)\n",
    "            dataprep_time_list.append(dataprep_time)\n",
    "            eval_time_list.append(eval_time)\n",
    "\n",
    "            samples_list_dict = {'noise_factor':'Noise', 'shift_factor':'Shift_Factor', 'pitch_factor':'Pitch_Change', 'speed_rate':'Time_Stretched',\n",
    "                                 'time_crop_factor':'Time_DataCrop_Factor', 'freq_crop_factor':'Freq_DataCrop_Factor', 'reflection_factor':'Reflection_Factor'}\n",
    "            # if noise is augmented, put units at the end of the samples_list element\n",
    "            unit_list_dict = {'noise_factor':'dBs', 'shift_factor':'', 'pitch_factor':' semiNote', 'speed_rate':'',\n",
    "                                 'time_crop_factor':'', 'freq_crop_factor':'', 'reflection_factor':''}\n",
    "            # value format separation works if the decimal factors are put in the format z.xy..., due to the basic slicing\n",
    "            augmentation_value_dict = {'noise_factor':'SNR:' + str(aug_value), 'shift_factor':pos_factor_percentage(aug_value), 'pitch_factor':str(aug_value), 'speed_rate':factor_percentage(aug_value),\n",
    "                                 'time_crop_factor':pos_factor_percentage(aug_value), 'freq_crop_factor':pos_factor_percentage(aug_value), 'reflection_factor':pos_factor_percentage(aug_value)}\n",
    "            samples_list.append(samples_list_dict[aug_method] + ', ' + augmentation_value_dict[aug_method] + unit_list_dict[aug_method])\n",
    "            \n",
    "        \n",
    "        dummy_idx += 1\n",
    "\n",
    "print(len(samples_list), test_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b3cd5ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T04:04:07.676235Z",
     "iopub.status.busy": "2024-09-07T04:04:07.675701Z",
     "iopub.status.idle": "2024-09-07T04:04:07.727468Z",
     "shell.execute_reply": "2024-09-07T04:04:07.726242Z"
    },
    "papermill": {
     "duration": 0.954838,
     "end_time": "2024-09-07T04:04:07.730314",
     "exception": false,
     "start_time": "2024-09-07T04:04:06.775476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Samples  Validation Accuracy  Training Accuracy  \\\n",
      "0                 NoAugmentation             0.860742           0.980760   \n",
      "1                Noise, SNR:0dBs             0.449840           0.522828   \n",
      "2                Noise, SNR:5dBs             0.678882           0.786074   \n",
      "3               Noise, SNR:10dBs             0.798442           0.928081   \n",
      "4               Noise, SNR:12dBs             0.822721           0.949916   \n",
      "5               Noise, SNR:15dBs             0.841961           0.968239   \n",
      "6               Noise, SNR:20dBs             0.858910           0.977706   \n",
      "7            Shift_Factor, 5.00%             0.861200           0.979997   \n",
      "8           Shift_Factor, 15.00%             0.861200           0.980608   \n",
      "9           Shift_Factor, 35.00%             0.861658           0.980760   \n",
      "10   Pitch_Change, 0.05 semiNote             0.827760           0.941976   \n",
      "11    Pitch_Change, 0.1 semiNote             0.827302           0.936173   \n",
      "12   Pitch_Change, 0.25 semiNote             0.789281           0.887006   \n",
      "13    Pitch_Change, 0.5 semiNote             0.727439           0.797068   \n",
      "14      Pitch_Change, 1 semiNote             0.637197           0.685143   \n",
      "15       Time_Stretched, -10.00%             0.820431           0.936479   \n",
      "16        Time_Stretched, -5.00%             0.812185           0.931593   \n",
      "17        Time_Stretched, 10.00%             0.828676           0.942587   \n",
      "18   Time_DataCrop_Factor, 5.00%             0.858910           0.977096   \n",
      "19  Time_DataCrop_Factor, 10.00%             0.858452           0.974500   \n",
      "20  Time_DataCrop_Factor, 20.00%             0.853413           0.962437   \n",
      "21  Time_DataCrop_Factor, 50.00%             0.828676           0.929302   \n",
      "22   Freq_DataCrop_Factor, 5.00%             0.832341           0.942434   \n",
      "23  Freq_DataCrop_Factor, 10.00%             0.787448           0.896778   \n",
      "24  Freq_DataCrop_Factor, 20.00%             0.734311           0.829287   \n",
      "25  Freq_DataCrop_Factor, 50.00%             0.661017           0.748359   \n",
      "26      Reflection_Factor, 5.00%             0.774164           0.886090   \n",
      "27     Reflection_Factor, 10.00%             0.801191           0.904108   \n",
      "28     Reflection_Factor, 20.00%             0.815850           0.924874   \n",
      "29     Reflection_Factor, 50.00%             0.818140           0.937090   \n",
      "\n",
      "    Data Creation Time  Evaluation Time  \n",
      "0            19.365833         0.066668  \n",
      "1            19.279886         0.086835  \n",
      "2            18.232325         0.092692  \n",
      "3            18.174952         0.074784  \n",
      "4            17.993691         0.083297  \n",
      "5            18.005435         0.067339  \n",
      "6            17.902086         0.069751  \n",
      "7            17.924253         0.076223  \n",
      "8            17.937122         0.081579  \n",
      "9            17.845537         0.073419  \n",
      "10           26.663377         0.072153  \n",
      "11           26.436572         0.066041  \n",
      "12           26.559042         0.078785  \n",
      "13           26.625991         0.069375  \n",
      "14           26.880605         0.069598  \n",
      "15           26.735090         0.068543  \n",
      "16           26.399857         0.067924  \n",
      "17           25.383476         0.069221  \n",
      "18           17.931535         0.069614  \n",
      "19           18.004354         0.074110  \n",
      "20           18.154225         0.075590  \n",
      "21           18.230945         0.069809  \n",
      "22           18.021890         0.068989  \n",
      "23           17.936107         0.070776  \n",
      "24           17.980991         0.071431  \n",
      "25           17.907458         0.067856  \n",
      "26           18.079389         0.090696  \n",
      "27           18.080733         0.065384  \n",
      "28           18.199667         0.069143  \n",
      "29           18.237762         0.070569  \n"
     ]
    }
   ],
   "source": [
    "test_results_dict = {\n",
    "    'Samples':['NoAugmentation'] + samples_list,\n",
    "    'Validation Accuracy': [test_result_noaug] + validation_acc_list,\n",
    "    'Training Accuracy': [train_result_noaug] + train_acc_list,\n",
    "    'Data Creation Time': [time_elapsed_no_aug] + dataprep_time_list,\n",
    "    'Evaluation Time': [eval_time_noaug] + eval_time_list\n",
    "}\n",
    "test_results = pd.DataFrame(test_results_dict)\n",
    "test_results.set_index(\"Samples\")\n",
    "\n",
    "print(test_results)\n",
    "test_results.to_csv(\"Efficient_Augmentation_Selection_Results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 500970,
     "sourceId": 928025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5518832,
     "sourceId": 9332754,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 24385415,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 195300738,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37311.458775,
   "end_time": "2024-09-07T04:04:11.981962",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-06T17:42:20.523187",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
